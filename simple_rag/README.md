# ğŸ‡»ğŸ‡³ Simple RAG - Há»‡ thá»‘ng Chatbot PhÃ¡p luáº­t Viá»‡t Nam

> **Há»‡ thá»‘ng RAG (Retrieval-Augmented Generation) hoÃ n toÃ n local cho tÃ i liá»‡u phÃ¡p luáº­t Viá»‡t Nam**

[![Python](https://img.shields.io/badge/Python-3.8%2B-blue)](https://python.org)
[![Ollama](https://img.shields.io/badge/Ollama-Local%20AI-green)](https://ollama.ai)
[![Streamlit](https://img.shields.io/badge/Streamlit-Web%20UI-red)](https://streamlit.io)
[![License](https://img.shields.io/badge/License-MIT-yellow)](LICENSE)

## ğŸ¯ Giá»›i thiá»‡u

Simple RAG lÃ  má»™t há»‡ thá»‘ng chatbot thÃ´ng minh Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘áº·c biá»‡t cho viá»‡c tra cá»©u vÃ  tÆ° váº¥n phÃ¡p luáº­t Viá»‡t Nam. Há»‡ thá»‘ng sá»­ dá»¥ng cÃ´ng nghá»‡ RAG (Retrieval-Augmented Generation) Ä‘á»ƒ tráº£ lá»i cÃ¢u há»i dá»±a trÃªn tÃ i liá»‡u phÃ¡p luáº­t cÃ³ sáºµn.

### âœ¨ TÃ­nh nÄƒng ná»•i báº­t

- ğŸ  **HoÃ n toÃ n Local**: KhÃ´ng cáº§n internet, khÃ´ng cÃ³ chi phÃ­ API
- ğŸ”’ **Báº£o máº­t tuyá»‡t Ä‘á»‘i**: Dá»¯ liá»‡u khÃ´ng rá»i khá»i mÃ¡y tÃ­nh cá»§a báº¡n
- ğŸ‡»ğŸ‡³ **Tá»‘i Æ°u tiáº¿ng Viá»‡t**: Sá»­ dá»¥ng mÃ´ hÃ¬nh AI chuyÃªn biá»‡t cho tiáº¿ng Viá»‡t
- ğŸ“š **Äa Ä‘á»‹nh dáº¡ng**: Há»— trá»£ PDF, DOCX, TXT
- ğŸŒ **Giao diá»‡n web**: Dá»… sá»­ dá»¥ng vá»›i Streamlit
- âš¡ **Hiá»‡u suáº¥t cao**: Xá»­ lÃ½ nhanh vá»›i ChromaDB

## ğŸš€ Báº¯t Ä‘áº§u nhanh

### YÃªu cáº§u há»‡ thá»‘ng
- **Python**: 3.8 - 3.13
- **RAM**: 8GB+ (khuyáº¿n nghá»‹ 16GB)
- **á»” cá»©ng**: 10GB+ trá»‘ng
- **Ollama**: Äá»ƒ cháº¡y mÃ´ hÃ¬nh AI local

### CÃ i Ä‘áº·t nhanh

1. **CÃ i Ä‘áº·t Ollama vÃ  táº£i mÃ´ hÃ¬nh**:
   ```bash
   # Táº£i Ollama tá»« https://ollama.ai
   ollama pull deepseek-r1         # MÃ´ hÃ¬nh ngÃ´n ngá»¯ tiáº¿ng Viá»‡t
   ollama pull mxbai-embed-large   # MÃ´ hÃ¬nh embedding
   ```

2. **CÃ i Ä‘áº·t Python dependencies**:
   ```bash
   git clone <repository-url>
   cd simple_rag
   pip install -r requirements.txt
   ```

3. **Kiá»ƒm tra há»‡ thá»‘ng**:
   ```bash
   python test_complete_local_rag.py
   # Káº¿t quáº£: Final result: PASS âœ…
   ```

4. **Cháº¡y giao diá»‡n web**:
   ```bash
   streamlit run src/web_interface.py
   ```

Truy cáº­p: http://localhost:8501

> ğŸ“– **Chi tiáº¿t cÃ i Ä‘áº·t**: Xem [SETUP.md](SETUP.md) Ä‘á»ƒ cÃ³ hÆ°á»›ng dáº«n Ä‘áº§y Ä‘á»§

## ğŸ—ï¸ Kiáº¿n trÃºc há»‡ thá»‘ng

```mermaid
graph TD
    A[TÃ i liá»‡u phÃ¡p luáº­t] --> B[Document Processor]
    B --> C[Text Chunking]
    C --> D[Embedding Generator]
    D --> E[Vector Store - ChromaDB]
    
    F[CÃ¢u há»i ngÆ°á»i dÃ¹ng] --> G[Query Processing]
    G --> H[Vector Search]
    E --> H
    H --> I[Relevant Documents]
    I --> J[LLM - DeepSeek-R1]
    J --> K[CÃ¢u tráº£ lá»i]
```

### CÃ¡c thÃ nh pháº§n chÃ­nh

| ThÃ nh pháº§n | MÃ´ táº£ | CÃ´ng nghá»‡ |
|------------|-------|-----------|
| **Document Processor** | Xá»­ lÃ½ vÃ  chia nhá» tÃ i liá»‡u | PyPDF2, python-docx |
| **Embedding Generator** | Táº¡o vector embedding | Ollama (mxbai-embed-large) |
| **Vector Store** | LÆ°u trá»¯ vÃ  tÃ¬m kiáº¿m vector | ChromaDB |
| **LLM Client** | Táº¡o cÃ¢u tráº£ lá»i | Ollama (deepseek-r1) |
| **Web Interface** | Giao diá»‡n ngÆ°á»i dÃ¹ng | Streamlit |

## ğŸ“ Cáº¥u trÃºc dá»± Ã¡n

```
simple_rag/
â”œâ”€â”€ ğŸ“„ README.md                    # TÃ i liá»‡u chÃ­nh
â”œâ”€â”€ ğŸ“„ SETUP.md                     # HÆ°á»›ng dáº«n cÃ i Ä‘áº·t chi tiáº¿t
â”œâ”€â”€ ğŸ“„ requirements.txt             # Dependencies Python
â”œâ”€â”€ âš™ï¸ config.py                    # Cáº¥u hÃ¬nh há»‡ thá»‘ng
â”œâ”€â”€ ğŸ§ª test_complete_local_rag.py   # Test há»‡ thá»‘ng hoÃ n chá»‰nh
â”œâ”€â”€ ğŸ§ª test_local_embeddings.py     # Test embedding
â”œâ”€â”€ ğŸ“‚ src/                         # Source code
â”‚   â”œâ”€â”€ ğŸ“„ document_processor.py    # Xá»­ lÃ½ tÃ i liá»‡u
â”‚   â”œâ”€â”€ ğŸ“„ embeddings.py           # Táº¡o embedding
â”‚   â”œâ”€â”€ ğŸ“„ vector_store.py         # Quáº£n lÃ½ vector database
â”‚   â”œâ”€â”€ ğŸ“„ rag_pipeline.py         # Logic RAG chÃ­nh
â”‚   â”œâ”€â”€ ğŸ“„ llm_client.py           # Client LLM
â”‚   â””â”€â”€ ğŸ“„ web_interface.py        # Giao diá»‡n web
â”œâ”€â”€ ğŸ“‚ data/                        # Dá»¯ liá»‡u
â”‚   â”œâ”€â”€ ğŸ“‚ raw/                     # TÃ i liá»‡u gá»‘c
â”‚   â””â”€â”€ ğŸ“‚ processed/               # TÃ i liá»‡u Ä‘Ã£ xá»­ lÃ½
â””â”€â”€ ğŸ“‚ models/                      # MÃ´ hÃ¬nh vÃ  vector database
    â””â”€â”€ ğŸ“‚ chromadb/                # ChromaDB storage
```

## ğŸ® CÃ¡ch sá»­ dá»¥ng

### 1. ThÃªm tÃ i liá»‡u

Äáº·t cÃ¡c file tÃ i liá»‡u phÃ¡p luáº­t vÃ o thÆ° má»¥c `data/raw/`:

```bash
# VÃ­ dá»¥
cp luat_giao_thong_duong_bo.pdf data/raw/
cp luat_dat_dai_2023.docx data/raw/
cp quy_dinh_ve_phat_giao_thong.txt data/raw/
```

### 2. Sá»­ dá»¥ng giao diá»‡n web

```bash
streamlit run src/web_interface.py
```

**TÃ­nh nÄƒng giao diá»‡n**:
- ğŸ’¬ Chat trá»±c tiáº¿p vá»›i AI
- ğŸ“Š Hiá»ƒn thá»‹ Ä‘á»™ tin cáº­y cá»§a cÃ¢u tráº£ lá»i
- ğŸ“„ Xem tÃ i liá»‡u nguá»“n Ä‘Æ°á»£c sá»­ dá»¥ng
- ğŸ”„ Táº£i láº¡i tÃ i liá»‡u má»›i

### 3. Sá»­ dá»¥ng tá»« command line

```bash
# Setup há»‡ thá»‘ng tá»« Ä‘áº§u
python main.py setup

# Test há»‡ thá»‘ng
python main.py test

# Cháº¡y web interface
python main.py web
```

### 4. VÃ­ dá»¥ cÃ¢u há»i

**Luáº­t giao thÃ´ng**:
- "Tá»‘c Ä‘á»™ tá»‘i Ä‘a cá»§a xe mÃ¡y trong khu vá»±c Ä‘Ã´ng dÃ¢n cÆ° lÃ  bao nhiÃªu?"
- "Äiá»u kiá»‡n Ä‘á»ƒ Ä‘Æ°á»£c cáº¥p giáº¥y phÃ©p lÃ¡i xe háº¡ng A1?"
- "Má»©c pháº¡t cho vi pháº¡m vÆ°á»£t Ä‘Ã¨n Ä‘á»?"

**Luáº­t Ä‘áº¥t Ä‘ai**:
- "Quyá»n sá»­ dá»¥ng Ä‘áº¥t cÃ³ thá»i háº¡n lÃ  bao lÃ¢u?"
- "Äiá»u kiá»‡n chuyá»ƒn nhÆ°á»£ng quyá»n sá»­ dá»¥ng Ä‘áº¥t?"
- "Thá»§ tá»¥c cáº¥p giáº¥y chá»©ng nháº­n quyá»n sá»­ dá»¥ng Ä‘áº¥t?"

## âš™ï¸ Cáº¥u hÃ¬nh

### Cáº¥u hÃ¬nh cÆ¡ báº£n

```python
# config.py
LLM_PROVIDER = "ollama"              # Sá»­ dá»¥ng Ollama local
EMBEDDING_PROVIDER = "ollama"        # Embedding local
LLM_MODEL = "deepseek-r1"            # MÃ´ hÃ¬nh tiáº¿ng Viá»‡t
EMBEDDING_MODEL = "mxbai-embed-large" # MÃ´ hÃ¬nh embedding
```

### Cáº¥u hÃ¬nh nÃ¢ng cao

```python
# Äiá»u chá»‰nh hiá»‡u suáº¥t
CHUNK_SIZE = 1000                    # KÃ­ch thÆ°á»›c Ä‘oáº¡n vÄƒn báº£n
SIMILARITY_THRESHOLD = 0.3           # NgÆ°á»¡ng tÆ°Æ¡ng Ä‘á»“ng
TOP_K_RESULTS = 5                    # Sá»‘ káº¿t quáº£ tráº£ vá»
TEMPERATURE = 0.7                    # Äá»™ sÃ¡ng táº¡o AI

# ÄÆ°á»ng dáº«n
DATA_DIR = "data"
RAW_DOCS_DIR = "data/raw"
PROCESSED_DOCS_DIR = "data/processed"
```

### Sá»­ dá»¥ng OpenAI (tÃ¹y chá»n)

```python
# config.py
LLM_PROVIDER = "openai"
EMBEDDING_PROVIDER = "openai"

# .env
OPENAI_API_KEY=your_api_key_here
```

## ğŸ§ª Testing

### Test tá»± Ä‘á»™ng

```bash
# Test há»‡ thá»‘ng hoÃ n chá»‰nh
python test_complete_local_rag.py

# Test embedding
python test_local_embeddings.py

# Test vá»›i Ollama
python test_ollama_rag.py
```

### Test thá»§ cÃ´ng

1. **Kiá»ƒm tra Ollama**:
   ```bash
   ollama list
   curl http://localhost:11434/api/tags
   ```

2. **Kiá»ƒm tra Python packages**:
   ```bash
   pip list | grep -E "(openai|chromadb|streamlit)"
   ```

## ğŸ“Š Hiá»‡u suáº¥t

### Thá»i gian xá»­ lÃ½
- **Embedding**: ~1-2 giÃ¢y/tÃ i liá»‡u
- **Truy váº¥n**: ~3-5 giÃ¢y
- **Khá»Ÿi Ä‘á»™ng**: ~10-15 giÃ¢y (láº§n Ä‘áº§u)

### Sá»­ dá»¥ng tÃ i nguyÃªn
- **RAM**: 4-6GB khi cháº¡y
- **á»” cá»©ng**: ~6GB (mÃ´ hÃ¬nh + database)
- **CPU**: Äa lÃµi

### Äá»™ chÃ­nh xÃ¡c
- **Retrieval**: 85-90% (tÃ¹y thuá»™c vÃ o cháº¥t lÆ°á»£ng tÃ i liá»‡u)
- **Generation**: 80-85% (tÃ¹y thuá»™c vÃ o Ä‘á»™ phá»©c táº¡p cÃ¢u há»i)

## ğŸ”§ Troubleshooting

### Lá»—i thÆ°á»ng gáº·p

| Lá»—i | NguyÃªn nhÃ¢n | Giáº£i phÃ¡p |
|-----|-------------|-----------|
| `Connection refused` | Ollama khÃ´ng cháº¡y | `ollama serve` |
| `Model not found` | MÃ´ hÃ¬nh chÆ°a táº£i | `ollama pull deepseek-r1` |
| `Out of memory` | RAM khÃ´ng Ä‘á»§ | ÄÃ³ng app khÃ¡c, giáº£m CHUNK_SIZE |
| `Unicode error` | Python version | Sá»­ dá»¥ng Python 3.8-3.13 |

### Debug

```bash
# Kiá»ƒm tra log chi tiáº¿t
python test_complete_local_rag.py --verbose

# Kiá»ƒm tra tráº¡ng thÃ¡i Ollama
ollama ps

# Kiá»ƒm tra ChromaDB
ls -la models/chromadb/
```

## ğŸš€ Roadmap

### PhiÃªn báº£n hiá»‡n táº¡i (v1.0)
- âœ… RAG hoÃ n toÃ n local
- âœ… Há»— trá»£ tiáº¿ng Viá»‡t
- âœ… Giao diá»‡n web Streamlit
- âœ… Äa Ä‘á»‹nh dáº¡ng tÃ i liá»‡u

### PhiÃªn báº£n tÆ°Æ¡ng lai
- ğŸ”„ Há»— trá»£ thÃªm Ä‘á»‹nh dáº¡ng (HTML, Markdown)
- ğŸ”„ TÃ­ch há»£p OCR cho PDF scan
- ğŸ”„ API REST cho tÃ­ch há»£p
- ğŸ”„ Dashboard quáº£n lÃ½ tÃ i liá»‡u
- ğŸ”„ Há»— trá»£ Ä‘a ngÃ´n ngá»¯

## ğŸ¤ ÄÃ³ng gÃ³p

ChÃºng tÃ´i hoan nghÃªnh má»i Ä‘Ã³ng gÃ³p! CÃ¡ch Ä‘Ã³ng gÃ³p:

1. **Fork** repository
2. **Táº¡o branch** cho feature má»›i
3. **Commit** thay Ä‘á»•i
4. **Push** lÃªn branch
5. **Táº¡o Pull Request**

### CÃ¡c lÄ©nh vá»±c cáº§n Ä‘Ã³ng gÃ³p
- ğŸ› Bug fixes
- âœ¨ TÃ­nh nÄƒng má»›i
- ğŸ“š Cáº£i thiá»‡n tÃ i liá»‡u
- ğŸ§ª Test cases
- ğŸŒ Há»— trá»£ ngÃ´n ngá»¯

## ğŸ“„ License

Dá»± Ã¡n nÃ y Ä‘Æ°á»£c phÃ¢n phá»‘i dÆ°á»›i giáº¥y phÃ©p MIT. Xem file [LICENSE](LICENSE) Ä‘á»ƒ biáº¿t thÃªm chi tiáº¿t.

## ğŸ™ Acknowledgments

- **Ollama**: CÃ´ng cá»¥ cháº¡y mÃ´ hÃ¬nh AI local
- **ChromaDB**: Vector database hiá»‡u suáº¥t cao
- **Streamlit**: Framework web app nhanh chÃ³ng
- **DeepSeek**: MÃ´ hÃ¬nh AI tá»‘i Æ°u cho tiáº¿ng Viá»‡t
- **mxbai**: MÃ´ hÃ¬nh embedding cháº¥t lÆ°á»£ng cao



---

<div align="center">

**â­ Náº¿u dá»± Ã¡n há»¯u Ã­ch, hÃ£y cho chÃºng tÃ´i má»™t star! â­**

Made with â¤ï¸ for Vietnamese legal community

</div>