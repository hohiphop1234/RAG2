# HÆ°á»›ng dáº«n CÃ i Ä‘áº·t RAG System

## ğŸ“‹ Tá»•ng quan

Há»‡ thá»‘ng RAG (Retrieval-Augmented Generation) hoÃ n toÃ n local cho tÃ i liá»‡u phÃ¡p luáº­t Viá»‡t Nam. Há»‡ thá»‘ng nÃ y cho phÃ©p báº¡n Ä‘áº·t cÃ¢u há»i vá» luáº­t giao thÃ´ng vÃ  Ä‘áº¥t Ä‘ai mÃ  khÃ´ng cáº§n káº¿t ná»‘i internet sau khi cÃ i Ä‘áº·t.

## ğŸ¯ TÃ­nh nÄƒng chÃ­nh

- âœ… **Xá»­ lÃ½ hoÃ n toÃ n local**: KhÃ´ng cáº§n API key, khÃ´ng cÃ³ chi phÃ­
- âœ… **Báº£o máº­t dá»¯ liá»‡u**: Táº¥t cáº£ dá»¯ liá»‡u Ä‘Æ°á»£c xá»­ lÃ½ trÃªn mÃ¡y tÃ­nh cá»§a báº¡n
- âœ… **Há»— trá»£ tiáº¿ng Viá»‡t**: Tá»‘i Æ°u cho tÃ i liá»‡u phÃ¡p luáº­t Viá»‡t Nam
- âœ… **Giao diá»‡n web**: Dá»… sá»­ dá»¥ng vá»›i Streamlit
- âœ… **Äa Ä‘á»‹nh dáº¡ng**: Há»— trá»£ .txt, .pdf, .docx

## ğŸ”§ YÃªu cáº§u há»‡ thá»‘ng

### Pháº§n cá»©ng tá»‘i thiá»ƒu
- **RAM**: 8GB (khuyáº¿n nghá»‹ 16GB)
- **á»” cá»©ng**: 10GB trá»‘ng
- **CPU**: Intel/AMD 64-bit

### Pháº§n má»m
- **Python**: 3.8 - 3.13 (trÃ¡nh 3.14 alpha)
- **Ollama**: Äá»ƒ cháº¡y mÃ´ hÃ¬nh AI local
- **Git**: Äá»ƒ clone repository

## ğŸ“¥ CÃ i Ä‘áº·t tá»«ng bÆ°á»›c

### BÆ°á»›c 1: CÃ i Ä‘áº·t Ollama

1. **Táº£i Ollama**:
   - Truy cáº­p [ollama.ai](https://ollama.ai/)
   - Táº£i phiÃªn báº£n phÃ¹ há»£p vá»›i há»‡ Ä‘iá»u hÃ nh cá»§a báº¡n
   - CÃ i Ä‘áº·t theo hÆ°á»›ng dáº«n

2. **Táº£i cÃ¡c mÃ´ hÃ¬nh cáº§n thiáº¿t**:
   ```bash
   # MÃ´ hÃ¬nh ngÃ´n ngá»¯ (8.2B tham sá»‘, tá»‘i Æ°u cho tiáº¿ng Viá»‡t)
   ollama pull deepseek-r1
   
   # MÃ´ hÃ¬nh embedding (334M tham sá»‘, 1024 chiá»u)
   ollama pull mxbai-embed-large
   ```

3. **Kiá»ƒm tra Ollama hoáº¡t Ä‘á»™ng**:
   ```bash
   ollama list
   ```
   Báº¡n sáº½ tháº¥y 2 mÃ´ hÃ¬nh Ä‘Ã£ táº£i.

### BÆ°á»›c 2: CÃ i Ä‘áº·t Python Environment

1. **Clone repository**:
   ```bash
   git clone <repository-url>
   cd simple_rag
   ```

2. **Táº¡o virtual environment**:
   ```bash
   # Windows
   python -m venv .venv
   .venv\Scripts\activate
   
   # macOS/Linux
   python3 -m venv .venv
   source .venv/bin/activate
   ```

3. **CÃ i Ä‘áº·t dependencies**:
   ```bash
   pip install -r requirements.txt
   ```

### BÆ°á»›c 3: Cáº¥u hÃ¬nh há»‡ thá»‘ng

1. **Kiá»ƒm tra cáº¥u hÃ¬nh** (Ä‘Ã£ Ä‘Æ°á»£c thiáº¿t láº­p sáºµn):
   ```python
   # config.py - Cáº¥u hÃ¬nh máº·c Ä‘á»‹nh
   LLM_PROVIDER = "ollama"                    # Sá»­ dá»¥ng Ollama local
   EMBEDDING_PROVIDER = "ollama"              # Embedding local
   LLM_MODEL = "deepseek-r1"                  # MÃ´ hÃ¬nh tiáº¿ng Viá»‡t
   EMBEDDING_MODEL = "mxbai-embed-large"      # MÃ´ hÃ¬nh embedding cháº¥t lÆ°á»£ng cao
   ```

2. **Táº¡o file .env** (tÃ¹y chá»n):
   ```bash
   # Copy tá»« file máº«u
   cp env_example.txt .env
   # Chá»‰nh sá»­a náº¿u cáº§n thiáº¿t
   ```

### BÆ°á»›c 4: Kiá»ƒm tra cÃ i Ä‘áº·t

1. **Test há»‡ thá»‘ng hoÃ n chá»‰nh**:
   ```bash
   python test_complete_local_rag.py
   ```
   Káº¿t quáº£ mong Ä‘á»£i: `Final result: PASS âœ…`

2. **Test embedding**:
   ```bash
   python test_local_embeddings.py
   ```
   Káº¿t quáº£ mong Ä‘á»£i: `Local embedding test PASSED âœ…`

## ğŸš€ Sá»­ dá»¥ng há»‡ thá»‘ng

### 1. ThÃªm tÃ i liá»‡u

Äáº·t cÃ¡c file tÃ i liá»‡u phÃ¡p luáº­t vÃ o thÆ° má»¥c `data/raw/`:
```bash
# VÃ­ dá»¥
cp luat_giao_thong.pdf data/raw/
cp luat_dat_dai.docx data/raw/
```

**Äá»‹nh dáº¡ng há»— trá»£**:
- `.txt` - VÄƒn báº£n thuáº§n
- `.pdf` - TÃ i liá»‡u PDF
- `.docx` - TÃ i liá»‡u Word

### 2. Cháº¡y giao diá»‡n web

```bash
# Tá»« thÆ° má»¥c gá»‘c cá»§a project
streamlit run src/web_interface.py
```

Truy cáº­p: http://localhost:8501

### 3. Sá»­ dá»¥ng tá»« command line

```bash
# Setup há»‡ thá»‘ng
python main.py setup

# Test há»‡ thá»‘ng
python main.py test

# Cháº¡y web interface
python main.py web
```

## âš™ï¸ Cáº¥u hÃ¬nh nÃ¢ng cao

### Äiá»u chá»‰nh hiá»‡u suáº¥t

```python
# config.py
CHUNK_SIZE = 1000              # KÃ­ch thÆ°á»›c Ä‘oáº¡n vÄƒn báº£n
SIMILARITY_THRESHOLD = 0.3     # NgÆ°á»¡ng tÆ°Æ¡ng Ä‘á»“ng (tháº¥p hÆ¡n = tÃ¬m nhiá»u hÆ¡n)
TOP_K_RESULTS = 5              # Sá»‘ lÆ°á»£ng káº¿t quáº£ tráº£ vá»
TEMPERATURE = 0.7              # Äá»™ sÃ¡ng táº¡o cá»§a AI (0.0-1.0)
```

### Sá»­ dá»¥ng OpenAI (tÃ¹y chá»n)

Náº¿u muá»‘n sá»­ dá»¥ng OpenAI thay vÃ¬ local:

1. **ThÃªm API key**:
   ```bash
   # Trong file .env
   OPENAI_API_KEY=your_key_here
   ```

2. **Cáº­p nháº­t config**:
   ```python
   # config.py
   LLM_PROVIDER = "openai"
   EMBEDDING_PROVIDER = "openai"
   ```

## ğŸ” Troubleshooting

### Lá»—i thÆ°á»ng gáº·p

1. **"Connection refused"**:
   - Kiá»ƒm tra Ollama Ä‘ang cháº¡y: `ollama list`
   - Khá»Ÿi Ä‘á»™ng láº¡i Ollama náº¿u cáº§n

2. **"Model not found"**:
   - Táº£i láº¡i mÃ´ hÃ¬nh: `ollama pull deepseek-r1`
   - Kiá»ƒm tra tÃªn mÃ´ hÃ¬nh trong config.py

3. **"Out of memory"**:
   - ÄÃ³ng cÃ¡c á»©ng dá»¥ng khÃ¡c
   - Giáº£m CHUNK_SIZE trong config.py
   - Sá»­ dá»¥ng mÃ´ hÃ¬nh nhá» hÆ¡n

4. **Unicode errors**:
   - Sá»­ dá»¥ng Python 3.13 hoáº·c tháº¥p hÆ¡n
   - TrÃ¡nh Python 3.14 alpha

### Kiá»ƒm tra há»‡ thá»‘ng

```bash
# Kiá»ƒm tra Ollama
curl http://localhost:11434/api/tags

# Kiá»ƒm tra Python packages
pip list | grep -E "(openai|chromadb|streamlit)"

# Kiá»ƒm tra dung lÆ°á»£ng
ollama ps
```

## ğŸ“Š Hiá»‡u suáº¥t há»‡ thá»‘ng

### Thá»i gian xá»­ lÃ½
- **Embedding**: ~1-2 giÃ¢y/tÃ i liá»‡u
- **Truy váº¥n**: ~3-5 giÃ¢y (bao gá»“m tÃ¬m kiáº¿m + táº¡o cÃ¢u tráº£ lá»i)
- **Khá»Ÿi Ä‘á»™ng**: ~10-15 giÃ¢y (táº£i mÃ´ hÃ¬nh láº§n Ä‘áº§u)

### Sá»­ dá»¥ng tÃ i nguyÃªn
- **RAM**: 4-6GB khi cháº¡y
- **á»” cá»©ng**: ~6GB cho mÃ´ hÃ¬nh Ollama + vector database
- **CPU**: Sá»­ dá»¥ng Ä‘a lÃµi khi cÃ³ thá»ƒ

## ğŸ¯ VÃ­ dá»¥ sá»­ dá»¥ng

### CÃ¢u há»i máº«u
- "Luáº­t giao thÃ´ng Ä‘Æ°á»ng bá»™ quy Ä‘á»‹nh gÃ¬ vá» tá»‘c Ä‘á»™ xe mÃ¡y?"
- "Äiá»u kiá»‡n Ä‘á»ƒ Ä‘Æ°á»£c cáº¥p giáº¥y phÃ©p lÃ¡i xe lÃ  gÃ¬?"
- "Luáº­t Ä‘áº¥t Ä‘ai quy Ä‘á»‹nh gÃ¬ vá» quyá»n sá»­ dá»¥ng Ä‘áº¥t?"
- "Xá»­ pháº¡t vi pháº¡m giao thÃ´ng nhÆ° tháº¿ nÃ o?"

### Cáº¥u trÃºc thÆ° má»¥c sau cÃ i Ä‘áº·t
```
simple_rag/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/           # TÃ i liá»‡u gá»‘c
â”‚   â””â”€â”€ processed/     # TÃ i liá»‡u Ä‘Ã£ xá»­ lÃ½
â”œâ”€â”€ models/
â”‚   â””â”€â”€ chromadb/      # Vector database
â”œâ”€â”€ src/               # Source code
â”œâ”€â”€ .env               # Environment variables
â”œâ”€â”€ config.py          # Cáº¥u hÃ¬nh há»‡ thá»‘ng
â””â”€â”€ requirements.txt   # Dependencies
```

## âœ… Kiá»ƒm tra cuá»‘i cÃ¹ng

Sau khi cÃ i Ä‘áº·t, cháº¡y lá»‡nh sau Ä‘á»ƒ Ä‘áº£m báº£o má»i thá»© hoáº¡t Ä‘á»™ng:

```bash
python test_complete_local_rag.py
```

Náº¿u tháº¥y `Final result: PASS âœ…`, há»‡ thá»‘ng Ä‘Ã£ sáºµn sÃ ng sá»­ dá»¥ng!

## ğŸ†˜ Há»— trá»£

Náº¿u gáº·p váº¥n Ä‘á»:
1. Kiá»ƒm tra pháº§n Troubleshooting á»Ÿ trÃªn
2. Äáº£m báº£o Ä‘Ã£ cÃ i Ä‘áº·t Ä‘Ãºng cÃ¡c yÃªu cáº§u
3. Kiá»ƒm tra log lá»—i chi tiáº¿t
4. Thá»­ cháº¡y láº¡i tá»« Ä‘áº§u náº¿u cáº§n

---

**ChÃºc báº¡n sá»­ dá»¥ng há»‡ thá»‘ng hiá»‡u quáº£! ğŸš€**